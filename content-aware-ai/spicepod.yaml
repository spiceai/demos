version: v1beta1
kind: Spicepod
name: content-aware-ai

datasets:
  # Application data (PostgreSQL)
  - from: postgres:syncs
    name: daily_journal
    params:
      pg_host: aws-0-us-west-1.pooler.supabase.com
      pg_db: postgres
      pg_port: 5432
      pg_user: 'postgres.tjtwkekeblroqgenheef'
      pg_sslmode: require
    embeddings:
      - column: answer
        use: openai_embeddings

  - from: postgres:syncs
    name: daily_journal_accelerated
    params:
      pg_host: aws-0-us-west-1.pooler.supabase.com
      pg_db: postgres
      pg_port: 5432
      pg_user: 'postgres.tjtwkekeblroqgenheef'
      pg_sslmode: require
    acceleration:
      enabled: true
    embeddings:
      - column: answer
        use: openai_embeddings

  # Datalake data (Databricks)
  - from: databricks:hive_metastore.default.messages
    name: messages
    params:
      databricks_endpoint: adb-4473752745667967.7.azuredatabricks.net
      databricks_cluster_id: 0423-065654-nu3nflpo

  # Accelerated Datalake data (Databricks)
  - from: databricks:hive_metastore.default.messages
    name: messages_accelerated
    acceleration:
      enabled: true
    params:
      databricks_endpoint: adb-4473752745667967.7.azuredatabricks.net
      databricks_cluster_id: 0423-065654-nu3nflpo

  # general messages
  - from: postgres:aidemo_messages
    name: general
    params:
      pg_host: aws-0-us-west-1.pooler.supabase.com
      pg_db: postgres
      pg_port: 5432
      pg_user: 'postgres.tjtwkekeblroqgenheef'
      pg_sslmode: require
    embeddings:
      - column: text
        use: openai_embeddings

  # general messages accelerated
  - from: postgres:aidemo_messages
    name: general_accelerated
    params:
      pg_host: aws-0-us-west-1.pooler.supabase.com
      pg_db: postgres
      pg_port: 5432
      pg_user: 'postgres.tjtwkekeblroqgenheef'
      pg_sslmode: require
    acceleration:
      enabled: true
    embeddings:
      - column: text
        use: hf_baai_bge

  # File data, indexed using OpenAI embeddings
  - from: ftp://0.0.0.0/
    name: decisions
    params:
      file_format: md
      ftp_user: user
      ftp_pass: 123
    acceleration:
      enabled: true
    embeddings:
      - column: content
        use: openai_embeddings

  # File data, indexed using OpenAI embeddings
  - from: ftp://localhost
    name: decisions_ftp
    metadata: true
    params:
      file_format: md
      ftp_user: user
      ftp_pass: 123
    acceleration:
      enabled: true
      refresh_mode: full
      refresh_interval: 1m
    embeddings:
      - column: content
        use: openai_embeddings

embeddings:
  - from: openai
    name: openai_embeddings
    params:
      openai_api_key: '${ env: OPENAI_API_KEY }'
  - from: huggingface:huggingface.co/sentence-transformers/all-MiniLM-L6-v2
    name: hf_minilm
  - from: huggingface:huggingface.co/BAAI/bge-small-en-v1.5
    name: hf_baai_bge

models:
  - name: openai
    from: openai/gpt-4o-mini
    params:
      openai_api_key: '${ env: OPENAI_API_KEY }'

  - name: groq
    from: openai/mixtral-8x7b-32768 # llama3-8b-8192 # llama3-70b-8192  # llama3-8b-8192
    params:
      endpoint: https://api.groq.com/openai/v1
      openai_api_key: '${ env.SPICE_GROK_API_KEY_1 }'

  - name: groq2
    from: openai/mixtral-8x7b-32768 # llama3-8b-8192 # llama3-70b-8192  # llama3-8b-8192
    params:
      endpoint: https://api.groq.com/openai/v1
      openai_api_key: '${ env.SPICE_GROK_API_KEY_2 }'

  # - name: lmstudio
  #   from: openai/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF
  #   params:
  #     endpoint: http://localhost:1234/v1
